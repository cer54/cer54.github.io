---
layout: page
title: "Gaussian Processes for Machine Learning: Book webpage"
permalink: /gpml/
---
<html>
  <head>
    <style type="text/css">
      body {font-family: Verdana,Arial,Helvetica,sans-serif; font-size: 16px}
    </style>
  </head>

  <body>
<center>
<h2>Gaussian Processes for Machine Learning</h2>
Carl Edward Rasmussen and Christopher K. I. Williams<br>
The MIT Press, 2006. ISBN 0-262-18253-X.
</center>

<p>
<center>
<img align="top" border="1" src="./rwcover.gif" alt="">
</center>
</p>
    
<p>
  <center>
    <table width="100%" cellpadding="3" border="0">
    <tr><td #ffffff>
    [ <a href="chapters">Contents</a>
    | <a href="code">Software</a>
    | <a href="data">Datasets</a>
 | <a href="errata.html">Errata</a> 
 | <a href="authors.html">Authors</a> 
 | <a href="order.html">Order</a> 
 ]
</td></tr></table>
  </center>
    </p>

<p> Gaussian processes (GPs) provide a principled, practical, probabilistic
approach to learning in kernel machines. GPs have received increased attention
in the machine-learning community over the past decade, and this book provides
a long-needed systematic and unified treatment of theoretical and practical
aspects of GPs in machine learning. The treatment is comprehensive and
self-contained, targeted at researchers and students in machine learning and
applied statistics.</p>

<p> The book deals with the supervised-learning problem for both regression and
classification, and includes detailed algorithms. A wide variety of covariance
(kernel) functions are presented and their properties discussed. Model
selection is discussed both from a Bayesian and a classical perspective. Many
connections to other well-known techniques from machine learning and statistics
are discussed, including support-vector machines, neural networks, splines,
regularization networks, relevance vector machines and others. Theoretical
issues including learning curves and the PAC-Bayesian framework are treated,
and several approximation methods for learning with large datasets are
discussed. The book contains illustrative examples and exercises, and code and
datasets are available on the Web. Appendixes provide mathematical background
and a discussion of Gaussian Markov processes.</p>

<p>The book is available for <a href="chapters">download</a> in electronic
format.</p>

<p>The book was awarded the
2009 <a href="https://bayesian.org/project/degroot-prize">DeGroot
Prize</a> of the International Society for Bayesian Analysis.</p>

<hr>

<table width="100%"><tr><td>
This page was most recently updated by <a href="http://mlg.eng.cam.ac.uk/carl">Carl Edward Rasmussen</a> on April 1st, 2022.</td>

<td align="right">
<a href="http://t.extreme-dm.com/?login=gausspml"
target="_top"><img src="http://t1.extreme-dm.com/i.gif"
name="EXim" border="0" height="38" width="41"
alt="eXTReMe Tracker"></img></a>
<script type="text/javascript" language="javascript1.2"><!--
EXs=screen;EXw=EXs.width;navigator.appName!="Netscape"?
EXb=EXs.colorDepth:EXb=EXs.pixelDepth;//-->
</script><script type="text/javascript"><!--
var EXlogin='gausspml' // Login
var EXvsrv='s9' // VServer
navigator.javaEnabled()==1?EXjv="y":EXjv="n";
EXd=document;EXw?"":EXw="na";EXb?"":EXb="na";
EXd.write("<img src=http://e0.extreme-dm.com",
"/"+EXvsrv+".g?login="+EXlogin+"&amp;",
"jv="+EXjv+"&amp;j=y&amp;srw="+EXw+"&amp;srb="+EXb+"&amp;",
"l="+escape(EXd.referrer)+" height=1 width=1>");//-->
</script><noscript><img height="1" width="1" alt=""
src="http://e0.extreme-dm.com/s9.g?login=gausspml&amp;j=n&amp;jv=n"/>
</noscript>

</td></tr></table>

  </body>
</html>
